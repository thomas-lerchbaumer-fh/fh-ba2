% This file was created with JabRef 2.4.
% Encoding: Cp1252
@ARTICLE{review_ml_styles,
  author={Mahadevkar, Supriya V. and Khemani, Bharti and Patil, Shruti and Kotecha, Ketan and Vora, Deepali R. and Abraham, Ajith and Gabralla, Lubna Abdelkareim},
  journal={IEEE Access}, 
  title={A Review on Machine Learning Styles in Computer Vision—Techniques and Future Directions}, 
  year={2022},
  volume={10},
  number={},
  pages={107293-107329},
  doi={10.1109/ACCESS.2022.3209825}}



@article{rnn_time_series_predict,
  title={Recurrent neural networks for time series forecasting: Current status and future directions},
  author={Hewamalage, Hansika and Bergmeir, Christoph and Bandara, Kasun},
  journal={International Journal of Forecasting},
  volume={37},
  number={1},
  pages={388--427},
  year={2021},
  publisher={Elsevier}
}

@article{cont_imp,
author = {Singh, Jagdeep and Singh, Harwinder},
year = {2015},
month = {02},
pages = {75-119},
title = {Continuous improvement philosophy – literature review and directions},
volume = {22},
journal = {Benchmarking: An International Journal},
doi = {10.1108/BIJ-06-2012-0038}
}



@Article{smart_city,
AUTHOR = {Stübinger, Johannes and Schneider, Lucas},
TITLE = {Understanding Smart City—A Data-Driven Literature Review},
JOURNAL = {Sustainability},
VOLUME = {12},
YEAR = {2020},
NUMBER = {20},
ARTICLE-NUMBER = {8460},
URL = {https://www.mdpi.com/2071-1050/12/20/8460},
ISSN = {2071-1050},
ABSTRACT = {This paper systematically reviews the top 200 Google Scholar publications in the area of smart city with the aid of data-driven methods from the fields natural language processing and time series forecasting. Specifically, our algorithm crawls the textual information of the considered articles and uses the created ad-hoc database to identify the most relevant streams &ldquo;smart infrastructure&rdquo;, &ldquo;smart economy &amp; policy&rdquo;, &ldquo;smart technology&rdquo;, &ldquo;smart sustainability&rdquo;, and &ldquo;smart health&rdquo;. Next, we automatically assign each manuscript into these subject areas by dint of several interdisciplinary scientific methods. Each stream is evaluated in a deep-dive analysis by (i) creating a word cloud to find the most important keywords, (ii) examining the main contributions, and (iii) applying time series methodologies to determine the past and future relevance. Due to our large-scaled literature, an in-depth evaluation of each stream is possible, which ultimately reveals strengths and weaknesses. We hereby acknowledge that smart sustainability will come to the fore in the next years&mdash;this fact confirms the current trend, as minimizing the required input of energy, water, food, waste, heat output and air pollution is becoming increasingly important.},
DOI = {10.3390/su12208460}
}





@article{mae,
doi = {10.1088/1757-899X/324/1/012049},
url = {https://dx.doi.org/10.1088/1757-899X/324/1/012049},
year = {2018},
month = {mar},
publisher = {IOP Publishing},
volume = {324},
number = {1},
pages = {012049},
author = {Weijie Wang and Yanmin Lu},
title = {Analysis of the Mean Absolute Error (MAE) and the Root Mean Square Error (RMSE) in Assessing Rounding Model},
journal = {IOP Conference Series: Materials Science and Engineering},
abstract = {Most existing Collaborative Filtering (CF) algorithms predict a rating as the preference of an active user toward a given item, which is always a decimal fraction. Meanwhile, the actual ratings in most data sets are integers. In this paper, we discuss and demonstrate why rounding can bring different influences to these two metrics; prove that rounding is necessary in post-processing of the predicted ratings, eliminate of model prediction bias, improving the accuracy of the prediction. In addition, we also propose two new rounding approaches based on the predicted rating probability distribution, which can be used to round the predicted rating to an optimal integer rating, and get better prediction accuracy compared to the Basic Rounding approach. Extensive experiments on different data sets validate the correctness of our analysis and the effectiveness of our proposed rounding approaches.}
}

@article{data_aug,
title = {Data augmentation: A comprehensive survey of modern approaches},
journal = {Array},
volume = {16},
pages = {100258},
year = {2022},
issn = {2590-0056},
doi = {https://doi.org/10.1016/j.array.2022.100258},
url = {https://www.sciencedirect.com/science/article/pii/S2590005622000911},
author = {Alhassan Mumuni and Fuseini Mumuni},
keywords = {Review of data augmentation, Computer vision, Generative adversarial network, Meta-learning, Synthetic data, Machine learning},
abstract = {To ensure good performance, modern machine learning models typically require large amounts of quality annotated data. Meanwhile, the data collection and annotation processes are usually performed manually, and consume a lot of time and resources. The quality and representativeness of curated data for a given task is usually dictated by the natural availability of clean data in the particular domain as well as the level of expertise of developers involved. In many real-world application settings it is often not feasible to obtain sufficient training data. Currently, data augmentation is the most effective way of alleviating this problem. The main goal of data augmentation is to increase the volume, quality and diversity of training data. This paper presents an extensive and thorough review of data augmentation methods applicable in computer vision domains. The focus is on more recent and advanced data augmentation techniques. The surveyed methods include deeply learned augmentation strategies as well as feature-level and meta-learning-based data augmentation techniques. Data synthesis approaches based on realistic 3D graphics modeling, neural rendering, and generative adversarial networks are also covered. Different from previous surveys, we cover a more extensive array of modern techniques and applications. We also compare the performance of several state-of-the-art augmentation methods and present a rigorous discussion of the effectiveness of various techniques in different scenarios of use based on performance results on different datasets and tasks.}
}



@article{ym_practice,
  title={Introduction to the theory and practice of yield management},
  author={Netessine, Serguei and Shumsky, Robert},
  journal={INFORMS transactions on education},
  volume={3},
  number={1},
  pages={34--44},
  year={2002},
  publisher={Informs}
}

@INPROCEEDINGS{prediction_stock_market,
  author={Pahwa, Kunal and Agarwal, Neha},
  booktitle={2019 International Conference on Machine Learning, Big Data, Cloud and Parallel Computing (COMITCon)}, 
  title={Stock Market Analysis using Supervised Machine Learning}, 
  year={2019},
  volume={},
  number={},
  pages={197-200},
  doi={10.1109/COMITCon.2019.8862225}}
  
@book{hands_on_ML,
isbn = {9781098125974},
year = {2022},
title = {Hands-on machine learning with Scikit-Learn, Keras, and TensorFlow : concepts, tools, and techniques to build intelligent systems},
edition = {Third Edition.},
language = {eng},
author = {GÃ©ron, AurÃ©lien},
keywords = {Machine learning},
}


@misc{intro_ml,
isbn = {9783960101147},
year = {2018},
title = {Praxiseinstieg Machine Learning mit Scikit-Learn und TensorFlow : Konzepte, Tools und Techniken für intelligente Systeme},
edition = {1. Auflage.},
language = {ger},
author = {Géron, Aurélien},
keywords = {Künstliche Intelligenz ; Maschinelles Lernen ; Programmbibliothek ; Python Programmiersprache},
}


@INPROCEEDINGS{tf_ctr,
  author={Gulhane, Priyanka Rameshpant and Pradeep Kumar, T S},
  booktitle={2018 International Conference on Recent Trends in Advance Computing (ICRTAC)}, 
  title={TensorFlow Based Website Click through Rate (CTR) Prediction Using Heat maps}, 
  year={2018},
  volume={},
  number={},
  pages={97-102},
  doi={10.1109/ICRTAC.2018.8679129}}


@INPROCEEDINGS{bd_tf_price_forecasting,
  author={Dehghan-Banadaki, Ali and Taufik, Taufik and Feliachi, Ali},
  booktitle={2018 International Conference on Computational Science and Computational Intelligence (CSCI)}, 
  title={Big Data Analytics in a Day-Ahead Electricity Price Forecasting Using TensorFlow in Restructured Power Systems}, 
  year={2018},
  volume={},
  number={},
  pages={1065-1069},
  doi={10.1109/CSCI46756.2018.00207}}


@article{kpi_imrpove_businiess,
title = {KPI-Based Approach for Business Process Improvement},
journal = {Procedia Computer Science},
volume = {164},
pages = {265-270},
year = {2019},
note = {CENTERIS 2019 - International Conference on ENTERprise Information Systems / ProjMAN 2019 - International Conference on Project MANagement / HCist 2019 - International Conference on Health and Social Care Information Systems and Technologies, CENTERIS/ProjMAN/HCist 2019},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2019.12.182},
url = {https://www.sciencedirect.com/science/article/pii/S1877050919322215},
author = {Aicha Wannes and Sonia Ayachi Ghannouchi},
keywords = {Key Performance Indicator (KPI), Business Process Management, Business Process Model, Notation meta-model, SCRUM method, ScrumWise},
abstract = {Business Process Management is a contemporary approach with the main purpose of deploying, executing and continuously optimizing the different types of business processes and thus improving the agility of the organization. In this paper, we propose an approach to business process improvement based on key performance indicators during the Business Process Management lifecycle. We started by highlighting the life cycle of key performance indicators. Then our proposal was at meta-modeling level, adding performance indicators as concepts of the Business Process Model and Notation meta-model. This brought us to a new extension of this meta-model based on key performance indicators. The particular case of the Scrum agile development process is then considered as a case study. In this context, key performance indicators are proposed for this process and are classified according to the elements of the Scrum method. The proposed approach was tested by taking the example of a company using ScrumWise tool for conducting scrum developments. The developed prototype allowed a performance evaluation of the Scrum process through key performance indicators and a set of recommendations were proposed to help managing tasks and improving the adopted process.}
}

@article{yield_m,
title = {Yield management: an overview},
journal = {International Journal of Hospitality Management},
volume = {14},
number = {2},
pages = {139-150},
year = {1995},
issn = {0278-4319},
doi = {https://doi.org/10.1016/0278-4319(95)00013-3},
url = {https://www.sciencedirect.com/science/article/pii/0278431995000133},
author = {Kevin Donaghy and Una McMahon and David McDowell},
keywords = {hotel, accomodation, profit, Yield management, demand, supply},
abstract = {Yield Management has been succesfully adopted by the airline industry following deregulation in the late 1970's. In an hotel context, yield management—a profit maximization strategy—is concerned with the market sensitive pricing of fixed room capacity relative to specific market characteristics. The concept of yield management is reviewed and the authors present a comprehensive structured operational framework for management in the hospitality industry focusing on 10 key areas. The article concludes with a look at the future of Yield Management and some areas for further research.}
}

@INPROCEEDINGS{kpi_imrpove_decision_making,
  author={Martins de Andrade, Paulo Roberto and Sadaoui, Samira},
  booktitle={2017 IEEE International Conference on Systems, Man, and Cybernetics (SMC)}, 
  title={Improving business decision making based on KPI management system}, 
  year={2017},
  volume={},
  number={},
  pages={1280-1285},
  doi={10.1109/SMC.2017.8122789}}
  
  @INPROCEEDINGS{nn_1,
  author={Wang, Linkai and Chen, Jing and Wang, Wei and Song, Ruizhuo and Zhang, Zhaochong and Yang, Guowei},
  booktitle={2022 4th International Conference on Control and Robotics (ICCR)}, 
  title={Review of Time Series Traffic Forecasting Methods}, 
  year={2022},
  volume={},
  number={},
  pages={1-5},
  doi={10.1109/ICCR55715.2022.10053870}}

@ARTICLE{lstm_1,
  author={Hou, Chenyu and Wu, Jiawei and Cao, Bin and Fan, Jing},
  journal={Big Data Mining and Analytics}, 
  title={A deep-learning prediction model for imbalanced time series data forecasting}, 
  year={2021},
  volume={4},
  number={4},
  pages={266-278},
  doi={10.26599/BDMA.2021.9020011}}

@INPROCEEDINGS{nn_2,
  author={Istiake Sunny, Md. Arif and Maswood, Mirza Mohd Shahriar and Alharbi, Abdullah G.},
  booktitle={2020 2nd Novel Intelligent and Leading Emerging Sciences Conference (NILES)}, 
  title={Deep Learning-Based Stock Price Prediction Using LSTM and Bi-Directional LSTM Model}, 
  year={2020},
  volume={},
  number={},
  pages={87-92},
  doi={10.1109/NILES50944.2020.9257950}}

@INPROCEEDINGS{lstm_2,
  author={Deng, Jianguang and Jirutitijaroen, Panida},
  booktitle={2010 IEEE Conference on Cybernetics and Intelligent Systems}, 
  title={Short-term load forecasting using time series analysis: A case study for Singapore}, 
  year={2010},
  volume={},
  number={},
  pages={231-236},
  doi={10.1109/ICCIS.2010.5518553}}


@article{lstm_inventor,
author = {Hochreiter, Sepp and Schmidhuber, J\"{u}rgen},
title = {Long Short-Term Memory},
year = {1997},
issue_date = {November 15, 1997},
publisher = {MIT Press},
address = {Cambridge, MA, USA},
volume = {9},
number = {8},
issn = {0899-7667},
url = {https://doi.org/10.1162/neco.1997.9.8.1735},
doi = {10.1162/neco.1997.9.8.1735},
abstract = {Learning to store information over extended time intervals by recurrent backpropagation takes a very long time, mostly because of insufficient, decaying error backflow. We briefly review Hochreiter's (1991) analysis of this problem, then address it by introducing a novel, efficient, gradient based method called long short-term memory (LSTM). Truncating the gradient where this does not do harm, LSTM can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units. Multiplicative gate units learn to open and close access to the constant error flow. LSTM is local in space and time; its computational complexity per time step and weight is O. 1. Our experiments with artificial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with real-time recurrent learning, back propagation through time, recurrent cascade correlation, Elman nets, and neural sequence chunking, LSTM leads to many more successful runs, and learns much faster. LSTM also solves complex, artificial long-time-lag tasks that have never been solved by previous recurrent network algorithms.},
journal = {Neural Comput.},
month = {nov},
pages = {1735–1780},
numpages = {46}
}

@INPROCEEDINGS{rnn_moharm,
  author={Moharm, Karim and Eltahan, Mohamed and Elsaadany, Ehab},
  booktitle={2020 International Conference on Smart Grids and Energy Systems (SGES)}, 
  title={Wind Speed Forecast using LSTM and Bi-LSTM Algorithms over Gabal El-Zayt Wind Farm}, 
  year={2020},
  volume={},
  number={},
  pages={922-927},
  doi={10.1109/SGES51519.2020.00169}}

@INPROCEEDINGS{lstm_stock,
  author={Istiake Sunny, Md. Arif and Maswood, Mirza Mohd Shahriar and Alharbi, Abdullah G.},
  booktitle={2020 2nd Novel Intelligent and Leading Emerging Sciences Conference (NILES)}, 
  title={Deep Learning-Based Stock Price Prediction Using LSTM and Bi-Directional LSTM Model}, 
  year={2020},
  volume={},
  number={},
  pages={87-92},
  doi={10.1109/NILES50944.2020.9257950}}


@article{lstm_module,
author = {Kumar, Jitendra and Goomer, Rimsha and Singh, Ashutosh},
year = {2018},
month = {01},
pages = {676-682},
title = {Long Short Term Memory Recurrent Neural Network (LSTM-RNN) Based Workload Forecasting Model For Cloud Datacenters},
volume = {125},
journal = {Procedia Computer Science},
doi = {10.1016/j.procs.2017.12.087}
}

@INPROCEEDINGS{lstm_overcome_rnn_problem,
  author={Bodapati, Suraj and Bandarupally, Harika and Trupthi, M},
  booktitle={2020 IEEE 5th International Conference on Computing Communication and Automation (ICCCA)}, 
  title={COVID-19 Time Series Forecasting of Daily Cases, Deaths Caused and Recovered Cases using Long Short Term Memory Networks}, 
  year={2020},
  volume={},
  number={},
  pages={525-530},
  doi={10.1109/ICCCA49541.2020.9250863}}


@article{cnn_intro,
	title = {Time-series analysis with smoothed {Convolutional} {Neural} {Network}},
	volume = {9},
	issn = {2196-1115},
	url = {https://doi.org/10.1186/s40537-022-00599-y},
	doi = {10.1186/s40537-022-00599-y},
	abstract = {CNN originates from image processing and is not commonly known as a forecasting technique in time-series analysis which depends on the quality of input data. One of the methods to improve the quality is by smoothing the data. This study introduces a novel hybrid exponential smoothing using CNN called Smoothed-CNN (S-CNN). The method of combining tactics outperforms the majority of individual solutions in forecasting. The S-CNN was compared with the original CNN method and other forecasting methods such as Multilayer Perceptron (MLP) and Long Short-Term Memory (LSTM). The dataset is a year time-series of daily website visitors. Since there are no special rules for using the number of hidden layers, the Lucas number was used. The results show that S-CNN is better than MLP and LSTM, with the best MSE of 0.012147693 using 76 hidden layers at 80\%:20\% data composition.},
	number = {1},
	journal = {Journal of Big Data},
	author = {Wibawa, Aji Prasetya and Utama, Agung Bella Putra and Elmunsyah, Hakkun and Pujianto, Utomo and Dwiyanto, Felix Andika and Hernandez, Leonel},
	month = apr,
	year = {2022},
	pages = {44},
}
 
 
@Article{cnn_basic,
AUTHOR = {Taye, Mohammad Mustafa},
TITLE = {Theoretical Understanding of Convolutional Neural Network: Concepts, Architectures, Applications, Future Directions},
JOURNAL = {Computation},
VOLUME = {11},
YEAR = {2023},
NUMBER = {3},
ARTICLE-NUMBER = {52},
URL = {https://www.mdpi.com/2079-3197/11/3/52},
ISSN = {2079-3197},
ABSTRACT = {Convolutional neural networks (CNNs) are one of the main types of neural networks used for image recognition and classification. CNNs have several uses, some of which are object recognition, image processing, computer vision, and face recognition. Input for convolutional neural networks is provided through images. Convolutional neural networks are used to automatically learn a hierarchy of features that can then be utilized for classification, as opposed to manually creating features. In achieving this, a hierarchy of feature maps is constructed by iteratively convolving the input image with learned filters. Because of the hierarchical method, higher layers can learn more intricate features that are also distortion and translation invariant. The main goals of this study are to help academics understand where there are research gaps and to talk in-depth about CNN&rsquo;s building blocks, their roles, and other vital issues.},
DOI = {10.3390/computation11030052}
}

@article{cnn_basic2,
author = {LeCun, Yann and Bengio, Y. and Hinton, Geoffrey},
year = {2015},
month = {05},
pages = {436-44},
title = {Deep Learning},
volume = {521},
journal = {Nature},
doi = {10.1038/nature14539}
}



@article{cnn_basic3,
	title = {Convolutional neural networks: an overview and application in radiology},
	volume = {9},
	issn = {1869-4101},
	url = {https://doi.org/10.1007/s13244-018-0639-9},
	doi = {10.1007/s13244-018-0639-9},
	abstract = {Convolutional neural network (CNN), a class of artificial neural networks that has become dominant in various computer vision tasks, is attracting interest across a variety of domains, including radiology. CNN is designed to automatically and adaptively learn spatial hierarchies of features through backpropagation by using multiple building blocks, such as convolution layers, pooling layers, and fully connected layers. This review article offers a perspective on the basic concepts of CNN and its application to various radiological tasks, and discusses its challenges and future directions in the field of radiology. Two challenges in applying CNN to radiological tasks, small dataset and overfitting, will also be covered in this article, as well as techniques to minimize them. Being familiar with the concepts and advantages, as well as limitations, of CNN is essential to leverage its potential in diagnostic radiology, with the goal of augmenting the performance of radiologists and improving patient care.},
	number = {4},
	journal = {Insights into Imaging},
	author = {Yamashita, Rikiya and Nishio, Mizuho and Do, Richard Kinh Gian and Togashi, Kaori},
	month = aug,
	year = {2018},
	pages = {611--629},
}

@INPROCEEDINGS{cnn_vechicle,
  author={Čavor, Ivana and Djukanović, Slobodan},
  booktitle={2023 27th International Conference on Information Technology (IT)}, 
  title={Vehicle Speed Estimation From Audio Signals Using 1D Convolutional Neural Networks}, 
  year={2023},
  volume={},
  number={},
  pages={1-4},
  doi={10.1109/IT57431.2023.10078724}}



@Article{1d_cnn,
AUTHOR = {Guessoum, Sonia and Belda, Santiago and Ferrandiz, Jose M. and Modiri, Sadegh and Raut, Shrishail and Dhar, Sujata and Heinkelmann, Robert and Schuh, Harald},
TITLE = {The Short-Term Prediction of Length of Day Using 1D Convolutional Neural Networks (1D CNN)},
JOURNAL = {Sensors},
VOLUME = {22},
YEAR = {2022},
NUMBER = {23},
ARTICLE-NUMBER = {9517},
URL = {https://www.mdpi.com/1424-8220/22/23/9517},
PubMedID = {36502228},
ISSN = {1424-8220},
ABSTRACT = {Accurate Earth orientation parameter (EOP) predictions are needed for many applications, e.g., for the tracking and navigation of interplanetary spacecraft missions. One of the most difficult parameters to forecast is the length of day (LOD), which represents the variation in the Earth&rsquo;s rotation rate since it is primarily affected by the torques associated with changes in atmospheric circulation. In this study, a new-generation time-series prediction algorithm is developed. The one-dimensional convolutional neural network (1D CNN), which is one of the deep learning methods, is introduced to model and predict the LOD using the IERS EOP 14 C04 and axial Z component of the atmospheric angular momentum (AAM), which was taken from the German Research Centre for Geosciences (GFZ) since it is strongly correlated with the LOD changes. The prediction procedure operates as follows: first, we detrend the LOD and Z-component series using the LS method, then, we obtain the residual series of each one to be used in the 1D CNN prediction algorithm. Finally, we analyze the results before and after introducing the AAM function. The results prove the potential of the proposed method as an optimal algorithm to successfully reconstruct and predict the LOD for up to 7 days.},
DOI = {10.3390/s22239517}
}



@misc{bp_basic,
series = {Computational Intelligence},
abstract = {In diesem Buch werden alle Teilgebiete der KI kompakt, leicht verständlich und anwendungsbezogen vorgestellt. Der Autor kennt das Gebiet nicht nur bestens aus Forschung und praktischer Anwendung, sondern engagiert sich auch erfolgreich in der Lehre. Die Themen reichen von der klassischen Logik über das Schließen mit Unsicherheit und maschinelles Lernen bis hin zu Anwendungen wie Diagnosesysteme, lernfähige Roboter oder Kreativität in der KI. Sie profitieren von dem umfassenden Einblick in dieses faszinierende Teilgebiet der Informatik, wobei, abgesehen von grundlegenden Programmierkenntnissen sowie etwas Mathematik, alle Voraussetzungen für ein gutes Verständnis bereitgestellt werden. Sie gewinnen vertiefte Kenntnisse, z. B. hinsichtlich der wichtigsten Verfahren zur Repräsentation und Verarbeitung von Wissen und in dem immer wichtiger werdenden Gebiet des maschinellen Lernens. Vor allem der Anwendungsbezug steht im Fokus der Darstellung. Viele Übungsaufgaben mit Lösungen sowie eine strukturierte Liste mit Verweisen auf Literatur und Ressourcen im Web ermöglichen ein effektives und kurzweiliges Selbststudium. Der Inhalt Einführung • Intelligente Agenten • Logikbasiertes Schließen • Problemlösen und Suche • Schließen mit Unsicherheit (Bayes-Netze, Methode der Maximalen Entropie) • Maschinelles Lernen, Data Mining und Datenaufbereitung • Neuronale Netze inklusive Deep Learning mit Beispielprogrammen in Python • Lernen durch Verstärkung • Lösungen zu den Übungsaufgaben Die Zielgruppe Studierende Informatiker und Informatikerinnen Ingenieure und Ingenieurinnen Der Autor Dr. Wolfgang Ertel ist Leiter des Instituts für Künstliche Intelligenz an der Hochschule Ravensburg-Weingarten. Er ist Diplom-Physiker und arbeitet seit 1987 in KI-Forschungsprojekten. Seit 1994 ist er Professor an der Hochschule Ravensburg-Weingarten und hält Vorlesungen zur KI. An seinem Institut wird geforscht an Anwendungen des maschinellen Lernens unter anderem in der Industrie, in der Pflege und an lernfähigen intelligenten Servicerobotern für Menschen mit Behinderung. Daneben untersucht er die Auswirkungen von KI-Anwendungen auf das Gemeinwohl der Gesellschaft. 2006 erhielt er den Landeslehrpreis.},
isbn = {3-658-32075-3},
year = {2021},
title = {Grundkurs Künstliche Intelligenz : Eine praxisorientierte Einführung},
edition = {5th ed. 2021..},
language = {ger},
author = {Ertel, Wolfgang},
keywords = {Artificial intelligence},
}


@INPROCEEDINGS{fitting,
  author={Zhang, Haotian and Zhang, Lin and Jiang, Yuan},
  booktitle={2019 11th International Conference on Wireless Communications and Signal Processing (WCSP)}, 
  title={Overfitting and Underfitting Analysis for Deep Learning Based End-to-end Communication Systems}, 
  year={2019},
  volume={},
  number={},
  pages={1-6},
  doi={10.1109/WCSP.2019.8927876}}


@misc{activation,
      title={Activation Functions in Deep Learning: A Comprehensive Survey and Benchmark}, 
      author={Shiv Ram Dubey and Satish Kumar Singh and Bidyut Baran Chaudhuri},
      year={2022},
      eprint={2109.14545},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}


@INPROCEEDINGS{bi_di_1,
  author={Yang, SU},
  booktitle={2019 IEEE 3rd Information Technology, Networking, Electronic and Automation Control Conference (ITNEC)}, 
  title={Research on Network Behavior Anomaly Analysis Based on Bidirectional LSTM}, 
  year={2019},
  volume={},
  number={},
  pages={798-802},
  doi={10.1109/ITNEC.2019.8729475}}

@INPROCEEDINGS{bi_di_2,
  author={Prakash, Satya and Jalal, Anand Singh and Pathak, Pooja},
  booktitle={2023 6th International Conference on Information Systems and Computer Networks (ISCON)}, 
  title={Forecasting COVID-19 Pandemic using Prophet, LSTM, hybrid GRU-LSTM, CNN-LSTM, Bi-LSTM and Stacked-LSTM for India}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  doi={10.1109/ISCON57294.2023.10112065}}


@inproceedings{tanh,
author = {Namin, Ashkan and Leboeuf, Karl and Muscedere, Roberto and Wu, Huapeng and Ahmadi, Majid},
year = {2009},
month = {06},
pages = {2117 - 2120},
title = {Efficient hardware implementation of the hyperbolic tangent sigmoid function},
journal = {Proceedings - IEEE International Symposium on Circuits and Systems},
doi = {10.1109/ISCAS.2009.5118213}
}


@article{loss_func,
	title = {A {Comprehensive} {Survey} of {Loss} {Functions} in {Machine} {Learning}},
	volume = {9},
	issn = {2198-5812},
	url = {https://doi.org/10.1007/s40745-020-00253-5},
	doi = {10.1007/s40745-020-00253-5},
	abstract = {As one of the important research topics in machine learning, loss function plays an important role in the construction of machine learning algorithms and the improvement of their performance, which has been concerned and explored by many researchers. But it still has a big gap to summarize, analyze and compare the classical loss functions. Therefore, this paper summarizes and analyzes 31 classical loss functions in machine learning. Specifically, we describe the loss functions from the aspects of traditional machine learning and deep learning respectively. The former is divided into classification problem, regression problem and unsupervised learning according to the task type. The latter is subdivided according to the application scenario, and here we mainly select object detection and face recognition to introduces their loss functions. In each task or application, in addition to analyzing each loss function from formula, meaning, image and algorithm, the loss functions under the same task or application are also summarized and compared to deepen the understanding and provide help for the selection and improvement of loss function.},
	number = {2},
	journal = {Annals of Data Science},
	author = {Wang, Qi and Ma, Yue and Zhao, Kun and Tian, Yingjie},
	month = apr,
	year = {2022},
	pages = {187--212},
}

@INPROCEEDINGS{optimizer,
  author={Omar, Amri and Mohamed, Fri and Mohammed, Msaaf and Fouad, Belmajdoub},
  booktitle={2021 International Conference on Digital Age and Technological Advances for Sustainable Development (ICDATA)}, 
  title={The commonly used algorithms to optimize a neural network in supervised learning: Overview, and comparative study}, 
  year={2021},
  volume={},
  number={},
  pages={31-38},
  doi={10.1109/ICDATA52997.2021.00015}}



  @ARTICLE{otimizer_1,
  author={Sun, Shiliang and Cao, Zehui and Zhu, Han and Zhao, Jing},
  journal={IEEE Transactions on Cybernetics}, 
  title={A Survey of Optimization Methods From a Machine Learning Perspective}, 
  year={2020},
  volume={50},
  number={8},
  pages={3668-3681},
  doi={10.1109/TCYB.2019.2950779}}
  
 @article{optimizer_2,
author = {Desai, Chitra},
year = {2020},
month = {10},
pages = {},
title = {Comparative Analysis of Optimizers in Deep Neural Networks}}


@article{min_max,
author = {Boddy, Aaron and Hurst, William and Mackay, Michael and El Rhalibi, A.},
year = {2019},
month = {03},
pages = {1-1},
title = {Density-Based Outlier Detection for Safeguarding Electronic Patient Record Systems (January 2019)},
volume = {PP},
journal = {IEEE Access},
doi = {10.1109/ACCESS.2019.2906503}
}
@article{multi,
author = {Wang, Miss},
year = {2018},
month = {01},
pages = {253-260},
title = {Advanced Multivariate Time Series Forecasting Models},
volume = {14},
journal = {Journal of Mathematics and Statistics},
doi = {10.3844/jmssp.2018.253.260}
}


@INPROCEEDINGS{feature_eng,
  author={Li, Lei and Ou, Yihang and Wu, Yabin and Li, Qi and Chen, Daoxin},
  booktitle={2018 International Conference on Network Infrastructure and Digital Content (IC-NIDC)}, 
  title={Research on feature engineering for time series data mining}, 
  year={2018},
  volume={},
  number={},
  pages={431-435},
  doi={10.1109/ICNIDC.2018.8525561}}

@article{feature_eng_2,
author = {Bandara, Kasun and Bergmeir, Christoph and Smyl, Slawek},
year = {2019},
month = {08},
pages = {112896},
title = {Forecasting Across Time Series Databases using Recurrent Neural Networks on Groups of Similar Series: A Clustering Approach},
volume = {140},
journal = {Expert Systems with Applications},
doi = {10.1016/j.eswa.2019.112896}
}

@INPROCEEDINGS{retail,
  author={Vyas, Rut and As, Revathi},
  booktitle={2022 International Conference on Smart Technologies and Systems for Next Generation Computing (ICSTSN)}, 
  title={Seasonal Sales Prediction and Visualization for Walmart Retail Chain Using Time Series and Regression Analysis: A Comparative Study}, 
  year={2022},
  volume={},
  number={},
  pages={1-6},
  doi={10.1109/ICSTSN53084.2022.9761294}}


@INPROCEEDINGS{stock_market,
  author={Busu, Tengku Nurul Aimi Balqis Tengku Malim and Kamarudin, Saadi Ahmad and Ahad, Nor Aishah and Mamat, Nor Azura Md Ghani},
  booktitle={2022 IEEE International Conference on Computing (ICOCO)}, 
  title={Prediction of FTSE Bursa Malaysia KLCI Stock Market using LSTM Recurrent Neural Network}, 
  year={2022},
  volume={},
  number={},
  pages={415-418},
  doi={10.1109/ICOCO56118.2022.10031901}}


@inproceedings{health_care,
author = {Boukenze, Basma and Mousannif, Hajar and Haqiq, Abdelkrim},
year = {2016},
month = {04},
pages = {01-09},
title = {Predictive Analytics in Healthcare System Using Data Mining Techniques},
volume = {6},
journal = {Computer Science & Information Technology},
doi = {10.5121/csit.2016.60501}
}

@inproceedings{data_qual,
author = {Sessions, Valerie and Valtorta, Marco},
year = {2006},
month = {01},
pages = {485-498},
title = {The Effects of Data Quality on Machine Learning Algorithms.}
}

@inbook{intro_ml_1,
author = {Bontempi, Gianluca and Ben Taieb, Souhaib and Le Borgne, Yann-Aël},
year = {2013},
month = {01},
pages = {},
title = {Machine Learning Strategies for Time Series Forecasting},
volume = {138},
isbn = {978-3-642-36317-7},
journal = {Lecture Notes in Business Information Processing},
doi = {10.1007/978-3-642-36318-4_3}
}

@comment{jabref-meta: selector_publisher:}

@comment{jabref-meta: selector_author:}

@comment{jabref-meta: selector_journal:}

@comment{jabref-meta: selector_keywords:}

